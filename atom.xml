<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>木木的博客</title>
  
  <subtitle>木木的博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://pl741.github.io/"/>
  <updated>2019-09-17T09:31:47.512Z</updated>
  <id>http://pl741.github.io/</id>
  
  <author>
    <name>木木</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《Detecting Spacecraf Anomalies Using LSTMs and Nonparametric Dynamic Thresholding》</title>
    <link href="http://pl741.github.io/2019/09/16/%E3%80%8ADetecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding%E3%80%8B/"/>
    <id>http://pl741.github.io/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/</id>
    <published>2019-09-16T10:00:30.000Z</published>
    <updated>2019-09-17T09:31:47.512Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1802.04431.pdf" target="_blank" rel="noopener">Detecting Spacecraf Anomalies Using LSTMs and Nonparametric Dynamic Thresholding</a></p><h3 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h3><p>异常检测&emsp;神经网络&emsp;RNN&emsp;LSTM&emsp;时间序列</p><h3 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h3><h4 id="利用LSTMs进行遥测值预测"><a href="#利用LSTMs进行遥测值预测" class="headerlink" title="利用LSTMs进行遥测值预测"></a>利用LSTMs进行遥测值预测</h4><p>&emsp;&emsp;模型确定后，提供一种非参数、动态无监督的阈值方法来评估残差。</p><p>&emsp;&emsp;为每个单通道创建一个单独的模型，使用每个模型预测该通道的值。为每个通道单独建模还可以跟踪通道级别，实现航天器异常模式的细粒度检测。考虑时间序列$X=\left\{\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \ldots, \mathbf{x}^{(n)}\right\}$，其中时间序列中的每一步$\mathbf{x}^{(t)} \in R^{m}$为$m$维向量$\left\{x_{1}^{(t)}, x_{2}^{(t)}, \ldots, x_{m}^{(t)}\right\}$对应于输入向量，对于每个点$\mathbf{x}^{(t)}$，序列长度$l_s$决定输入模型进行预测的点的数量，预测长度$l_p$决定预测的步长，预测维度$d$的范围为$1 \leq d \leq m$。要预测单个通道的遥测值则$d=1$，同时使用$l_p=1$限制每个步骤$t$的预测数量，以减少运行时间。在每个步骤$t$为实际遥测值生成单个标量预测值$\hat{y}^{(t)}$。在本次实验中输入到LSTM中的$x^{(t)}$包括给定信道的先验遥测值和发送到航天器的编码命令信息。发出命令的模块和发送或接收命令的模块的组合是一个 one-hot 编码的模块，插入到每个步骤$t$中。</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/1.png" title="图1. 每个时间步长$t$预测所用输入矩阵的可视化表示。将当前预测误差与过去预测误差进行比较，以确定是否异常"><h4 id="动态误差阈值"><a href="#动态误差阈值" class="headerlink" title="动态误差阈值"></a>动态误差阈值</h4><p>&emsp;&emsp;本文提出一种方法，可以在不做对过去平滑误差分布做高斯假设的情况下有效地标识极值。每一步$t$产生一个预测值$\hat{y}^{(t)}$，预测误差$e^{(t)}=\left|y^{(t)}-\hat{y}^{(t)}\right|$，其中$y^{(t)}=x_{i}^{(t+1)}$，其中$i$对应于真实遥测值得维度，将每个误差$e^{(t)}$添加到一维误差$e$ 向量中，</p><script type="math/tex; mode=display">\mathbf{e}=\left[e^{(t-h)}, \ldots, e^{\left(t-l_{s}\right)}, \ldots, e^{(t-1)}, e^{(t)}\right]</script><p>其中$h$表示用于评估当前误差的历史误差值的数量，然后对误差集$\mathbf e$进行平滑以抑制LSTM预测中的尖锐误差值，这些尖锐误差会影响预测结果，即使在正常情况下，也会出现误差值的急剧峰值。本文使用指数加权平均（EWMA）来产生平滑误差$\mathbf{e}_{s}=\left[e_{s}^{(t-h)}, \ldots, e_{s}^{(t-l s)}, \ldots, e_{s}^{(t-1)}, e_{s}^{(t)}\right]$。为评估这些值是否为正常值，本文将为平滑预测误差设置一个阈值，将阈值以上的平滑预测误差值对应的值分类为异常。</p><p>&emsp;&emsp;<strong>阈值计算和异常评分</strong>：本文提出一种无监督的异常阈值计算方法，可以在低开销、不使用标记数据或误差统计假设的情况下实现高效的阈值计算。阈值$\epsilon$从以下集合中选出：</p><script type="math/tex; mode=display">\boldsymbol{\epsilon}=\mu\left(\mathbf{e}_{s}\right)+\mathbf{z} \sigma\left(\mathbf{e}_{s}\right)</script><p>其中$\epsilon$取决于：</p><script type="math/tex; mode=display">\epsilon=\arg \max (\boldsymbol{\epsilon})=\frac{\Delta \mu\left(\mathbf{e}_{s}\right) / \mu\left(\mathbf{e}_{s}\right)+\Delta \sigma\left(\mathbf{e}_{s}\right) / \sigma\left(\mathbf{e}_{s}\right)}{\left|\mathbf{e}_{a}\right|+\left|\mathbf{E}_{s e q}\right|^{2}}</script><p>其中：</p><script type="math/tex; mode=display">\begin{array}{l}{\Delta \mu\left(\mathbf{e}_{s}\right)=\mu\left(\mathbf{e}_{s}\right)-\mu\left(\left\{e_{s} \in \mathbf{e}_{s} | e_{s}<\epsilon\right\}\right)} \\ {\Delta \sigma\left(\mathbf{e}_{s}\right)=\sigma\left(\mathbf{e}_{s}\right)-\sigma\left(\left\{e_{s} \in \mathbf{e}_{s} | e_{s}<\epsilon\right\}\right)} \\ {\mathbf{e}_{a}=\left\{e_{s} \in \mathbf{e}_{s} | e_{s}>\epsilon\right\}} \\ {\mathbf{E}_{s e q}=\text { continuous sequences of } e_{a} \in \mathbf{e}_{a}}\end{array}</script><p>使用$z \in \mathbf{z}$来确定$\epsilon$的评估值，其中$\mathbf z$是一个有序正值集，表示标准差大于$\mu\left(\mathbf{e}_{s}\right)$的数量。$\mathbf z$的值取决于上下文，但根据实验结果，$2 - 10$之间的范围可以很好的工作。$z &lt;2$的值通常会导致过多的假阳性。一旦确定了$\arg \max (\boldsymbol{\epsilon})$，每个得到的平滑错误序列$\mathbf{e}_{s e q} \in \mathbf{E}_{s e q}$都会得到一个异常分数$s$，用来表示异常的严重程度：</p><script type="math/tex; mode=display">s^{(i)}=\frac{\max \left(\mathbf{e}_{s e q}^{(i)}\right)-\arg \max (\boldsymbol{\epsilon})}{\mu\left(\mathbf{e}_{s}\right)+\sigma\left(\mathbf{e}_{s}\right)}</script><p>也就是说，如果找到一个阈值，去掉超过它的所有值，平滑误差$\mathbf e_{s}$的均值和标准差都会下降最大的百分比。该函数还惩罚具有最大异常值$\left(\left|\mathbf{e}_{a}\right|\right)$和序列$\left(\left|\mathbf{E}_{s e q}\right|\right)$以防止过度贪心行为。然后根据每个异常误差序列到所选阈值的距离，给出平滑误差最大值的归一化分数。</p><h4 id="减少误报"><a href="#减少误报" class="headerlink" title="减少误报"></a>减少误报</h4><p>&emsp;&emsp;<strong>修剪异常</strong>：基于预测的异常检测方法的精度很大程度上取决于用于设置阈值和判定当前预测误差的历史数据量$(h)$。为了减少误报、限制内存和计算成本，我们引入了一个剪枝过程，创建一个新集合$\mathbf{e}_{m a x}$，包含按照降序排序的所有$\mathbf{e}_{s e q}$的$\max \left(\mathbf{e}_{s e q}\right)$。同时在$\mathbf e_{max}$的末尾添加一个非异常$\max \left(\left\{e_{s} \in \mathbf{e}_{s} \in \mathbf{E}_{s e q} | e_{s} \in \mathbf{e}_{a}\right\}\right)$的最大平滑误差。之后以增量的方式逐步执行序列，计算每一步的减少百分比$d^{(i)}=\left(e_{\max }^{(i-1)}-e_{\max }^{(i)}\right) / e_{\max }^{(i-1)}$，其中$i \in\left\{1,2, \ldots,\left(\left|\mathbf{E}_{s e q}\right|+1\right)\right\}$。如果在某个步骤$i$中，$d^{(i)}$超过了最小百分比降幅$p$，则所有$e_{m a x}^{(j)} \in \mathbf{e}_{m a x} | j&lt;i$及其对应的异常序列均为异常。如果$d^{(i)}$没有满足最小减少量$p$，对于所有后续平滑的误差序列$d^{(i)}, d^{(i+1)}, \ldots, d^{\left(i+\left|\mathbf{E}_{s e q}\right|+1\right)}$都将被重新分类为正常误差。这种剪枝有助于确保异常序列不是流中常规噪声的结果，并且可通过阈值处理来初始识别异常序列。将评估仅限于少数潜在异常序列中的最大误差比没有阈值处理所需的大量值 - 值比较要有效得多。</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/2.png" title="图2. 展示异常修剪过程的例子"><p>&emsp;&emsp;在这种情况下，$\mathbf{e}_{m a x}=[0.01396,0.01072,0.00994]$，最小下降百分比 $p=0.1$。从异常$2$到异常$1$的下降幅度为 $d^{(1)}=0.23&gt;p$，该序列保留为异常分类。从异常$1$到下一个最高平滑误差$\left(e_{s}=0.0099 \right)$的下降幅度为 $d^{(2)}=.07&lt;p$，因此这个序列被重新分类为正常序列。</p><p>&emsp;&emsp;<strong>学习历史数据</strong>：一旦收集到少量异常历史纪录或标记数据，就可以使用这种学习策略来抑制假阳性。基于相似度$s$的异常通常不会在同一频道内频繁重复出现的假设，可以设置最小分数$s_{min}$，以便在$\boldsymbol{s}&lt;\boldsymbol{s}_{\min }$时，将未来的异常重新分类为正常。最低分数只适用于系统产生异常率超过某一比率的数据通道，并为所有这些通道单独设置$s_{min}$。可以使用通道的先验异常得分来设置适当的$s_{min}$，具体取决于精确度和召回率之间的期望平衡。此外，如果异常检测系统有一种机制，用户可以通过该机制为异常提供标签，那么这些标签还可以用于为给定流设置$s_{min}$。例如，如果一个流或通道有多个合并的假阳性异常，那么$s_{min}$可以设置在这些假阳性异常分数的上界附近。</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/3.png" title="图3 包含上下文异常的遥测流命令信息编码"><p>&emsp;&emsp;这种异常不太可能使用基于限制或距离的方法进行识别。使用已编码的命令信息和信道的先前遥测值生成下一个时间步骤的预测，并产生误差。在这个例子中，一步预测和实际遥测值非常接近，如顶部时间序列所示。利用非参数阈值化方法设置误差阈值，得到标记异常区域内的两个预测异常序列，一个为假阳性，一个为真阳性。假阳性表明需要对序列进行修剪，如果该序列相对接近阈值以下的值，则将该序列重新分类为正常序列（参见图2）。</p><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>&emsp;&emsp;我们将异常分为两类：点异常和上下文异常，以区分可能由适当设置的警报或忽略时间信息的基于距离的方法（点异常）识别的异常和需要更复杂的方法（如LSTMs或分层时间记忆（HTM）方法）来检测（上下文异常）的异常。这个特征是从前面提到的三个类别中改编而来的——点异常、上下文异常、集合异常。由于上下文异常和集合异常都需要时间上下文，并且比较难以检测，因此它们都被合并到上下文类别中。</p><p>&emsp;&emsp;<strong>设置：</strong>对于主要发生在时间$t_{a}$包含一个或多个异常序列的每个唯一数据流，我们评估从$t_{s}=t_{a}-3 d$到$t_{f}=t_{a}+2 d$ 时间帧之间的所有遥测值， 其中$d$表示天。使用从$t_{s_{\text {train}}}=t_{s}-2 d$到$t_{f_{\text {train}}}=t_{s}$的值和命令数据为每个唯一流训练模型。如果在这些时间范围内没有足够的数据，则增加额外的天数。5天的异常周期被选择用来平衡两个目标：精度和计算成本。预测异常区域略微扩大，以便将扩展后重叠或邻近的异常区域合并为一个区域，来解释多个异常区域代表一个时间的情况。根据系统识别出的最后一组预测异常序列，对每个标记的遥测异常序列$x_{a} \in \mathbf{x}_{a}$按照下面规则进行评估：</p><p>&emsp;&emsp;（1）真阳性：</p><script type="math/tex; mode=display">\left|e_{a}^{(t)} \in e_{s e q} \in \mathbf{e}_{s e q} : x_{i}^{(t)} \in x_{a}\right|>0</script><p>&emsp;&emsp;对于任意的$x_{a} \in \mathbf{x}_{a}$，换句话说，预测异常序列的任何一部分都属于任何真实标记序列，则结果为真阳性。即使许多预测序列的一部分属于标记序列也仅纪录一个真阳性。</p><p>&emsp;&emsp;（2）如果没有预测序列与阳性标记序列重叠，标记为假阴性。</p><p>&emsp;&emsp;（3）所有没有与标记异常区域重叠的预测序列，标记为假阳性。</p><p>&emsp;&emsp;为简单起见，我们不会根据检测到异常的早期程度或误报与标记区域之间的距离进行评分调整。</p><p>&emsp;&emsp;<strong>批处理：</strong>遥测数据被聚合到一分钟窗口中，按照SMAP和当前系统实现的下行计划，以70分钟/组进行评估。使用$h=2100$计算每70分钟批处理的值，其中$h$是用于计算错误阈值和评估当前批处理的先前值的数量。该系统还非常适合以实时流式方式处理值。</p><p>&emsp;&emsp;<strong>模型参数和评估：</strong>在实验中所有模型使用相同的架构和参数：</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/4.png"><p>&emsp;&emsp;每个模型都是只含有两层隐藏层和80个（/层）单元的浅层模型。我们发现这种结构能够提供足够的能力来很好的预测单个通道，增加额外的能力在增加模型大小和训练时间的同时对提供预测效益没有任何用处。所有通道不一定都需要这么大的容量，未来的改进可能包括根据信道复杂度自动选择合适的模型容量。类似地，序列长度$l_{s}=250$提供了性能和训练时间之间的平衡。SMAP和MSL在输入维度上的差异是由于每个任务都有不同的命令模块集。在模型训练过程中，早期停止被用来防止过度拟合，并不是所有的模型都经过了完整35次迭代的训练。预测生成后，采用3.2节的方法计算平滑误差的异常阈值，其中$\mathbf{z}=\{2.5,3.0,3.5, \ldots, 10.0\}$，并且后续异常值之间的最小百分比只差$p=0.13$。参数$p$是控制精确度和召回率的重要标准，当标签可用时可推断出一个适当的值。在我们的设置中，在$0.05&lt;p&lt;0.20$达到了合理的结果。</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/5.png" title="图4 参数方法和本文提出的方法（标记为“非参数”）在不同参数设置下的总体精度和召回结果的比较的图。"><p>&emsp;&emsp;<strong>参数阈值比较：</strong>使用原始的LSTM进行误差预测，我们还使用参数误差评估方法生成异常，该方法与Numenta异常基准的最精确模型相协调。这种方法递增地处理原始误差-在每个步骤$t$，将历史误差的窗口$W$建模为正态分布，并且在每个步骤$t$更新均值$μ_{w}$和方差$σ_{W}^{2}$。我们设置$W$的长度为$l_{w}=h=2100$，并对两种方法使用相同的预测误差集。然后计算预测误差长度$l_{short}$的短期平均值$μ_{s}$，其平滑效果与第3.2节中的EWMA平滑相似。然后使用尾概率$Q$来定义异常$L$的可能性:</p><script type="math/tex; mode=display">L=1-Q\left(\frac{\mu_{s}-\mu_{W}}{\sigma_{W}^{2}}\right)</script><p>如果$L \geq 1-\epsilon_{n o r m}$的值为分类为异常。在下一节中，使用$l_{short}=10$和$\epsilon_{n o r m}=\{0.01,0.0001\}$生成的结果与3.2节中的方法进行比较。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1802.04431.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Detecting Spacecraf Anomalies Using LSTMs and Nonparametric
      
    
    </summary>
    
    
      <category term="机器学习" scheme="http://pl741.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="时间序列异常检测" scheme="http://pl741.github.io/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>使用链接</title>
    <link href="http://pl741.github.io/2019/09/16/%E9%93%BE%E6%8E%A5/"/>
    <id>http://pl741.github.io/2019/09/16/链接/</id>
    <published>2019-09-16T07:38:06.000Z</published>
    <updated>2019-09-16T10:09:59.426Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/4eaddcbe4d12" target="_blank" rel="noopener">搭建个人博客</a></p><p><a href="http://blog.rexking6.top/2017/03/30/hexo%E4%B8%BB%E9%A2%98%E5%92%8C%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E3%80%81%E6%89%93%E8%B5%8F%E3%80%81%E6%90%9C%E7%B4%A2%E3%80%81%E9%98%85%E8%AF%BB%E9%87%8F%E7%AD%89%E5%8A%9F%E8%83%BD/" target="_blank" rel="noopener">博客个性化设置</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/4eaddcbe4d12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;搭建个人博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.rexking6.top/2017/
      
    
    </summary>
    
    
    
      <category term="配置" scheme="http://pl741.github.io/tags/%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>机器学习评价标准</title>
    <link href="http://pl741.github.io/2019/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86/"/>
    <id>http://pl741.github.io/2019/09/16/机器学习评价标准/</id>
    <published>2019-09-16T05:38:06.000Z</published>
    <updated>2019-09-16T07:24:19.337Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本内容"><a href="#基本内容" class="headerlink" title="基本内容"></a>基本内容</h1><p><strong>True真&emsp; False假&emsp;Positive正&emsp;Negative负</strong></p><p>&emsp;&emsp;异常检测中，P和N一般是针对预测来说的，Positive正类指的是你更关心的那一类！即“异常”，P指预测为正类，即预测为异常。T和F针对预测与真实情况的比较， True指正确匹配，F指错误匹配。</p><div class="table-container"><table><thead><tr><th></th><th style="text-align:center">实际正例</th><th style="text-align:center">实际负例</th><th style="text-align:center"></th></tr></thead><tbody><tr><td>预测正例P</td><td style="text-align:center">TP</td><td style="text-align:center">FP</td><td style="text-align:center">所有预测为正的个数TP+FP</td></tr><tr><td>预测负例N</td><td style="text-align:center">FN</td><td style="text-align:center">TN</td><td style="text-align:center">所有预测为负的个数FN+TN</td></tr><tr><td></td><td style="text-align:center">所有实际正例的个数TP+FN</td><td style="text-align:center">所有实际负例的个数FP+TN</td></tr></tbody></table></div><img src="/2019/09/16/机器学习评价标准/72.png"><ul><li><p>TPR：真正类率，代表预测是异常实际也是异常的样本数，占实际总异常数的比例——值越大 性能越好</p></li><li><p>FPR：假正类率，代表预测是异常但实际是正常的样本数，占实际正常总数的比例——值越小 性能越好</p></li><li><p>R：召回率，意义同TPR——值越大 性能越好</p></li><li><p>P：精确率Precision，代表预测是异常实际也是异常的样本数，占预测是异常的总数的比例——值越大 性能越好</p></li><li><p>F：P和R的加权调和平均，常用的是F1值——值越大 性能越好</p></li><li><p>A：正确率Accuracy，与精确率的区别是，不仅考虑异常类也考虑正常类，即所有匹配样本数，占所有样本的比例——值越大 性能越好</p></li></ul><p>另外还有两个，分别为：虚警率和漏警率</p><ul><li>虚警率（<strong>False alarm</strong>）表示负类样本被分为正类样本在所有负类样本中的比例</li></ul><img src="/2019/09/16/机器学习评价标准/71.png"><ul><li>漏警率表示（漏警率表示（Missing alarm）表示正类样本被分为负类样本在所有正类样本中的比例Missing alarm）表示正类样本被分为负类样本在所有正类样本中的比例</li></ul><img src="/2019/09/16/机器学习评价标准/70.png"><h1 id="Tensorflow实现"><a href="#Tensorflow实现" class="headerlink" title="Tensorflow实现"></a>Tensorflow实现</h1><p><strong>&emsp;损失值：</strong><br>    tf.nn.softmax_cross_entropy_with_logits(logits, labels, name=None)<br><strong>&emsp;参数解析：</strong><br>&emsp; logits:神经网络最后一层的输出，如果有batch，大小为[batch_size, n_classes]<br>&emsp; labels:实际标签，大小同上</p><p><strong>&emsp;执行过程：</strong><br>&emsp;&emsp;先对网络最后一层的输出做一个softmax，通常是求取输出属于某一类的概率，对于单样本而言，输出就是一个num_classes大小的向量。</p><img src="/2019/09/16/机器学习评价标准/73.png"><p>&emsp;然后将softmax的输出向量与样本的实际标签做一个交叉熵。</p><img src="/2019/09/16/机器学习评价标准/74.png"><p>&emsp;其中 y’ 指代实际的标签中第i个的值（用mnist数据举例，如果是3，那么标签是[0，0，0，1，0，0，0，0，0，0]，除了第4个值为1，其他全为0）; y就是softmax的输出向量[Y1，Y2,Y3…]中，第i个元素的值</p><p>&emsp;&emsp;显而易见，预测越准确，结果的值越小（别忘了前面还有负号），最后求一个平均，得到我们想要的loss</p><p>&emsp;&emsp;注意！！！这个函数的返回值并不是一个数，而是一个向量，如果要求交叉熵，我们要再做一步tf.reduce_sum操作,就是对向量里面所有元素求和，最后才得到H(y)，如果求loss，则要做一步tf.reduce_mean操作，对向量求均值！</p><pre><code>tf.reduce_mean(input_tensor, axis=None,keep_dims=False,name=None,               reduction_indices=None)</code></pre><h4 id="参数解析"><a href="#参数解析" class="headerlink" title="参数解析"></a>参数解析</h4><ul><li>&emsp; 第一个参数input_tensor： 输入的待降维的tensor;</li><li>&emsp; 第二个参数axis： 指定的轴，如果不指定，则计算所有元素的均值;</li><li>&emsp; 第三个参数keep_dims：是否降维度，设置为True，输出的结果保持输入tensor的形状，设置为False，输出结果会降低维度;</li><li>&emsp; 第四个参数name： 操作的名称;</li><li>&emsp; 第五个参数 reduction_indices：在以前版本中用来指定轴，已弃用;</li></ul><p>&emsp;predict是预测结果，也就是神经网络的输出，real是真实的标签，sess就是tensorflow当前的会话，feed_dict是需要喂的数据。</p><p>&emsp;tf.equal(A, B)是对比这两个矩阵或者向量的相等的元素，如果是相等的那就返回True，反正返回False，返回的值的矩阵维度和A是一样的。</p><p>&emsp;tf.cast()函数的作用是执行 tensorflow 中张量数据类型转换，<br>    tf.cast(x, dtype, name=None)</p><h4 id="参数解析-1"><a href="#参数解析-1" class="headerlink" title="参数解析"></a>参数解析</h4><ul><li>&emsp;第一个参数 x:   待转换的数据（张量）</li><li>&emsp;第二个参数 dtype： 目标数据类型</li><li>&emsp;第三个参数 name： 可选参数，定义操作的名称</li></ul><p>&emsp;tf.loical_and()将数值变成逻辑值<br>    tf.logical_and(x, y, name=None)</p><p>&emsp;tf.argmax()返回值是是数值最大值的索引位置，如果最大值位置相同，则分类正确，反之则分类错误<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">predictions = tf.argmax(predict, <span class="number">1</span>)</span><br><span class="line">actuals = tf.argmax(real, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将上述获得的变量设置成元素为0或者为1的矩阵</span></span><br><span class="line">ones_like_actuals = tf.ones_like(actuals)</span><br><span class="line">zeros_like_actuals = tf.zeros_like(actuals)</span><br><span class="line">ones_like_predictions = tf.ones_like(predictions)</span><br><span class="line">zeros_like_predictions = tf.zeros_like(predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照前面的计算公式编写如下计算代码</span></span><br><span class="line"></span><br><span class="line">tp_op = tf.reduce_sum(tf.cast(tf.logical_and(</span><br><span class="line">            tf.equal(actuals, ones_like_actuals),</span><br><span class="line">            tf.equal(predictions, ones_like_predictions)),<span class="string">"float"</span>))</span><br><span class="line"> </span><br><span class="line">tn_op = tf.reduce_sum(tf.cast(tf.logical_and(</span><br><span class="line">            tf.equal(actuals, zeros_like_actuals),</span><br><span class="line">            tf.equal(predictions, zeros_like_predictions)),<span class="string">"float"</span>))</span><br><span class="line"> </span><br><span class="line">fp_op = tf.reduce_sum(tf.cast(tf.logical_and(</span><br><span class="line">            tf.equal(actuals, zeros_like_actuals),</span><br><span class="line">            tf.equal(predictions, ones_like_predictions)),<span class="string">"float"</span>))</span><br><span class="line"> </span><br><span class="line">fn_op = tf.reduce_sum(tf.cast(tf.logical_and(</span><br><span class="line">            tf.equal(actuals, ones_like_actuals),</span><br><span class="line">            tf.equal(predictions, zeros_like_predictions)),<span class="string">"float"</span>))</span><br><span class="line">            </span><br><span class="line">tp, tn, fp, fn = session.run([tp_op, tn_op, fp_op, fn_op], feed_dict)</span><br><span class="line">tpr = float(tp)/(float(tp) + float(fn))</span><br><span class="line">fpr = float(fp)/(float(fp) + float(tn))</span><br><span class="line">fnr = float(fn)/(float(tp) + float(fn))</span><br><span class="line">accuracy = (float(tp) + float(tn))/(float(tp) + float(fp) + float(fn) + float(tn))</span><br><span class="line">recall = tpr</span><br><span class="line">precision = float(tp)/(float(tp) + float(fp))</span><br><span class="line">f1_score = (<span class="number">2</span> * (precision * recall)) / (precision + recall)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本内容&quot;&gt;&lt;a href=&quot;#基本内容&quot; class=&quot;headerlink&quot; title=&quot;基本内容&quot;&gt;&lt;/a&gt;基本内容&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;True真&amp;emsp; False假&amp;emsp;Positive正&amp;emsp;Negative负&lt;/stro
      
    
    </summary>
    
    
    
      <category term="机器学习" scheme="http://pl741.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>jupyter主题设置</title>
    <link href="http://pl741.github.io/2019/09/16/jupyter_%E4%B8%BB%E9%A2%98%E8%AE%BE%E7%BD%AE/"/>
    <id>http://pl741.github.io/2019/09/16/jupyter_主题设置/</id>
    <published>2019-09-16T05:38:06.000Z</published>
    <updated>2019-09-16T09:57:34.711Z</updated>
    
    <content type="html"><![CDATA[<h2 id="jupyter-主题设置"><a href="#jupyter-主题设置" class="headerlink" title="jupyter 主题设置"></a>jupyter 主题设置</h2><p>安装主题：pip install jupyterthemes</p><p>如果之前安装过可以更新一下：pip install —upgrade jupyterthemes</p><p>设置主题：蓝色主题——jt -t onedork -fs 95 -altp -tfs 11 -nfs 115 -cellw 88% -T</p><p>​                    黑色主题——jt -t monokai -f fira -fs 13 -cellw 90% -ofs 11 -dfs 11 -T -N</p><p>​                    部分参数：-f(字体)  -fs(字体大小) -cellw(占屏比或宽度)  </p><p>​                                      -ofs(输出段的字号)  -T(显示工具栏)  -N(显示自己主机名)</p><h4 id="Conda环境自由切换："><a href="#Conda环境自由切换：" class="headerlink" title="Conda环境自由切换："></a>Conda环境自由切换：</h4><p>​        看一下是否已经把 Anaconda 中创建的所有定制环境作为核心添加在了 Jupyter Notebook 中。这样我们就能简单地利用 Kernel 按钮切换环境。换核的时候不需要重启 notebook。</p><p>​        假设你的 Anaconda 环中有两个自定义的环境 my_NLP 和 gym。按照下面的步骤将这些添加到你的 Jupyter Notebook 中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">conda activate my_NLP</span><br><span class="line"># Install the IPython Kernel </span><br><span class="line">pip install ipykernel</span><br><span class="line"># Link your environment with Jupyter </span><br><span class="line"># Repeat steps for the other environment, gym</span><br><span class="line">python -m ipykernel install --user --name=my_NLP</span><br><span class="line">pip install ipykernel </span><br><span class="line">python -m ipykernel install --user --name=gym</span><br></pre></td></tr></table></figure><p>​        现在打开你的 Jupyter Notebook，找到 kernel 按钮下的 Change Kernel 选项，接下来就是见证奇迹的时刻：所有的核都被列举出来了，你可以通过简单地点击来激活一个服务核。</p><h4 id="其他功能："><a href="#其他功能：" class="headerlink" title="其他功能："></a>其他功能：</h4><p>​        安装 nbextensions for Jupyter Notebooks</p><p>​        安装 nbextensions 是很容易的，简单地遵循下面的步骤就行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Stop and exit your Jupyter Notebook server </span><br><span class="line"># Make sure you are in the base environment</span><br><span class="line">conda activate base</span><br><span class="line"># Install the nbextensions </span><br><span class="line">pip install jupyter_contrib_nbextensions</span><br><span class="line"># Install the necessary JS and CSS files </span><br><span class="line">jupyter contrib nbextension install --system</span><br></pre></td></tr></table></figure><p>​        启动 Jupyter notebook 服务，你可以在起始页看到第四个叫做 Nbextensions 的选项。点击这个选项，然后就可以看到极妙的功能集，这些都是你一直希望在 Jupyter Notebooks 中拥有的。</p><p>其中一些的简单介绍：</p><p>​          Table of Contents(2)：单击生成整个笔记本的目录，不同的 section 都有对应的超链接。</p><p>​         Scratchpad：在我看来绝对是最好的扩展了。这是一个你可以在里面做代码实验的独立空间，不会干扰笔记本中的其他部分。</p><p>​        Codefolding ：代码折叠，这个不需要做过多的解释。</p><p>​        Hide Input All：隐藏所有的代码单元，同时保持所有的输出和 markdown 单元可见。如果你要向非技术人员解释你的结果，那么这就会是一个很有用的功能。</p><p>​        Variable Inspector：将你从调试的忧伤中拯救出来，这与 Spyder IDE 中的变量检查窗口有些类似。</p><p>​        Spellchecker：对 markdown 单元中的内容进行拼写检查。</p><p>​        Zenmode：移除掉屏幕中杂乱无关的内容，以便你能够聚焦于重要的东西上，例如代码。</p><p>​        Snippets Menu：从 list comprehension 到 pandas 以及它们之间的所有常用代码片段的一个很酷的集合。这是最好的部分？你可以修改窗口的小部件来添加你自己的定制片段。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;jupyter-主题设置&quot;&gt;&lt;a href=&quot;#jupyter-主题设置&quot; class=&quot;headerlink&quot; title=&quot;jupyter 主题设置&quot;&gt;&lt;/a&gt;jupyter 主题设置&lt;/h2&gt;&lt;p&gt;安装主题：pip install jupyterthemes
      
    
    </summary>
    
    
    
      <category term="配置" scheme="http://pl741.github.io/tags/%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
</feed>
