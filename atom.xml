<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>木木的博客</title>
  
  <subtitle>木木的博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://pl741.github.io/"/>
  <updated>2019-09-16T07:24:19.337Z</updated>
  <id>http://pl741.github.io/</id>
  
  <author>
    <name>木木</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习评价标准</title>
    <link href="http://pl741.github.io/2019/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86/"/>
    <id>http://pl741.github.io/2019/09/16/机器学习评价标准/</id>
    <published>2019-09-16T05:38:06.000Z</published>
    <updated>2019-09-16T07:24:19.337Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本内容"><a href="#基本内容" class="headerlink" title="基本内容"></a>基本内容</h1><p><strong>True真&emsp; False假&emsp;Positive正&emsp;Negative负</strong></p><p>&emsp;&emsp;异常检测中，P和N一般是针对预测来说的，Positive正类指的是你更关心的那一类！即“异常”，P指预测为正类，即预测为异常。T和F针对预测与真实情况的比较， True指正确匹配，F指错误匹配。</p><table><thead><tr><th></th><th align="center">实际正例</th><th align="center">实际负例</th><th align="center"></th></tr></thead><tbody><tr><td>预测正例P</td><td align="center">TP</td><td align="center">FP</td><td align="center">所有预测为正的个数TP+FP</td></tr><tr><td>预测负例N</td><td align="center">FN</td><td align="center">TN</td><td align="center">所有预测为负的个数FN+TN</td></tr><tr><td></td><td align="center">所有实际正例的个数TP+FN</td><td align="center">所有实际负例的个数FP+TN</td><td align="center"></td></tr></tbody></table><img src="/2019/09/16/机器学习评价标准/72.png"><ul><li><p>TPR：真正类率，代表预测是异常实际也是异常的样本数，占实际总异常数的比例——值越大 性能越好</p></li><li><p>FPR：假正类率，代表预测是异常但实际是正常的样本数，占实际正常总数的比例——值越小 性能越好</p></li><li><p>R：召回率，意义同TPR——值越大 性能越好</p></li><li><p>P：精确率Precision，代表预测是异常实际也是异常的样本数，占预测是异常的总数的比例——值越大 性能越好</p></li><li><p>F：P和R的加权调和平均，常用的是F1值——值越大 性能越好</p></li><li><p>A：正确率Accuracy，与精确率的区别是，不仅考虑异常类也考虑正常类，即所有匹配样本数，占所有样本的比例——值越大 性能越好</p></li></ul><p>另外还有两个，分别为：虚警率和漏警率</p><ul><li>虚警率（<strong>False alarm</strong>）表示负类样本被分为正类样本在所有负类样本中的比例</li></ul><img src="/2019/09/16/机器学习评价标准/71.png"><ul><li>漏警率表示（漏警率表示（Missing alarm）表示正类样本被分为负类样本在所有正类样本中的比例Missing alarm）表示正类样本被分为负类样本在所有正类样本中的比例</li></ul><img src="/2019/09/16/机器学习评价标准/70.png"><h1 id="Tensorflow实现"><a href="#Tensorflow实现" class="headerlink" title="Tensorflow实现"></a>Tensorflow实现</h1><p><strong>&emsp;损失值：</strong><br>    tf.nn.softmax_cross_entropy_with_logits(logits, labels, name=None)<br><strong>&emsp;参数解析：</strong><br>&emsp; logits:神经网络最后一层的输出，如果有batch，大小为[batch_size, n_classes]<br>&emsp; labels:实际标签，大小同上</p><p><strong>&emsp;执行过程：</strong><br>&emsp;&emsp;先对网络最后一层的输出做一个softmax，通常是求取输出属于某一类的概率，对于单样本而言，输出就是一个num_classes大小的向量。</p><img src="/2019/09/16/机器学习评价标准/73.png"><p>&emsp;然后将softmax的输出向量与样本的实际标签做一个交叉熵。</p><img src="/2019/09/16/机器学习评价标准/74.png"><p>&emsp;其中 y’ 指代实际的标签中第i个的值（用mnist数据举例，如果是3，那么标签是[0，0，0，1，0，0，0，0，0，0]，除了第4个值为1，其他全为0）; y就是softmax的输出向量[Y1，Y2,Y3…]中，第i个元素的值</p><p>&emsp;&emsp;显而易见，预测越准确，结果的值越小（别忘了前面还有负号），最后求一个平均，得到我们想要的loss</p><p>&emsp;&emsp;注意！！！这个函数的返回值并不是一个数，而是一个向量，如果要求交叉熵，我们要再做一步tf.reduce_sum操作,就是对向量里面所有元素求和，最后才得到H(y)，如果求loss，则要做一步tf.reduce_mean操作，对向量求均值！</p><pre><code>tf.reduce_mean(input_tensor, axis=None,keep_dims=False,name=None,               reduction_indices=None)</code></pre><h4 id="参数解析"><a href="#参数解析" class="headerlink" title="参数解析"></a>参数解析</h4><ul><li>&emsp; 第一个参数input_tensor： 输入的待降维的tensor;</li><li>&emsp; 第二个参数axis： 指定的轴，如果不指定，则计算所有元素的均值;</li><li>&emsp; 第三个参数keep_dims：是否降维度，设置为True，输出的结果保持输入tensor的形状，设置为False，输出结果会降低维度;</li><li>&emsp; 第四个参数name： 操作的名称;</li><li>&emsp; 第五个参数 reduction_indices：在以前版本中用来指定轴，已弃用;</li></ul><p>&emsp;predict是预测结果，也就是神经网络的输出，real是真实的标签，sess就是tensorflow当前的会话，feed_dict是需要喂的数据。</p><p>&emsp;tf.equal(A, B)是对比这两个矩阵或者向量的相等的元素，如果是相等的那就返回True，反正返回False，返回的值的矩阵维度和A是一样的。</p><p>&emsp;tf.cast()函数的作用是执行 tensorflow 中张量数据类型转换，<br>    tf.cast(x, dtype, name=None)</p><h4 id="参数解析-1"><a href="#参数解析-1" class="headerlink" title="参数解析"></a>参数解析</h4><ul><li>&emsp;第一个参数 x:   待转换的数据（张量）</li><li>&emsp;第二个参数 dtype： 目标数据类型</li><li>&emsp;第三个参数 name： 可选参数，定义操作的名称</li></ul><p>&emsp;tf.loical_and()将数值变成逻辑值<br>    tf.logical_and(x, y, name=None)</p><p>&emsp;tf.argmax()返回值是是数值最大值的索引位置，如果最大值位置相同，则分类正确，反之则分类错误</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">predictions = tf.argmax(predict, <span class="number">1</span>)</span><br><span class="line">actuals = tf.argmax(real, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将上述获得的变量设置成元素为0或者为1的矩阵</span></span><br><span class="line">ones_like_actuals = tf.ones_like(actuals)</span><br><span class="line">zeros_like_actuals = tf.zeros_like(actuals)</span><br><span class="line">ones_like_predictions = tf.ones_like(predictions)</span><br><span class="line">zeros_like_predictions = tf.zeros_like(predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照前面的计算公式编写如下计算代码</span></span><br><span class="line"></span><br><span class="line">tp_op = tf.reduce_sum(tf.cast(tf.logical_and(</span><br><span class="line">            tf.equal(actuals, ones_like_actuals),</span><br><span class="line">            tf.equal(predictions, ones_like_predictions)),<span class="string">"float"</span>))</span><br><span class="line"> </span><br><span class="line">tn_op = tf.reduce_sum(tf.cast(tf.logical_and(</span><br><span class="line">            tf.equal(actuals, zeros_like_actuals),</span><br><span class="line">            tf.equal(predictions, zeros_like_predictions)),<span class="string">"float"</span>))</span><br><span class="line"> </span><br><span class="line">fp_op = tf.reduce_sum(tf.cast(tf.logical_and(</span><br><span class="line">            tf.equal(actuals, zeros_like_actuals),</span><br><span class="line">            tf.equal(predictions, ones_like_predictions)),<span class="string">"float"</span>))</span><br><span class="line"> </span><br><span class="line">fn_op = tf.reduce_sum(tf.cast(tf.logical_and(</span><br><span class="line">            tf.equal(actuals, ones_like_actuals),</span><br><span class="line">            tf.equal(predictions, zeros_like_predictions)),<span class="string">"float"</span>))</span><br><span class="line">            </span><br><span class="line">tp, tn, fp, fn = session.run([tp_op, tn_op, fp_op, fn_op], feed_dict)</span><br><span class="line">tpr = float(tp)/(float(tp) + float(fn))</span><br><span class="line">fpr = float(fp)/(float(fp) + float(tn))</span><br><span class="line">fnr = float(fn)/(float(tp) + float(fn))</span><br><span class="line">accuracy = (float(tp) + float(tn))/(float(tp) + float(fp) + float(fn) + float(tn))</span><br><span class="line">recall = tpr</span><br><span class="line">precision = float(tp)/(float(tp) + float(fp))</span><br><span class="line">f1_score = (<span class="number">2</span> * (precision * recall)) / (precision + recall)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本内容&quot;&gt;&lt;a href=&quot;#基本内容&quot; class=&quot;headerlink&quot; title=&quot;基本内容&quot;&gt;&lt;/a&gt;基本内容&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;True真&amp;emsp; False假&amp;emsp;Positive正&amp;emsp;Negative负&lt;/stro
      
    
    </summary>
    
    
    
      <category term="机器学习" scheme="http://pl741.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>链接</title>
    <link href="http://pl741.github.io/2019/09/16/%E9%93%BE%E6%8E%A5/"/>
    <id>http://pl741.github.io/2019/09/16/链接/</id>
    <published>2019-09-16T05:12:47.841Z</published>
    <updated>2019-09-16T09:51:08.179Z</updated>
    
    <content type="html"><![CDATA[<p>搭建个人博客：<a href="https://www.jianshu.com/p/4eaddcbe4d12" target="_blank" rel="noopener">https://www.jianshu.com/p/4eaddcbe4d12</a></p><p>博客个性化设置：<a href="http://blog.rexking6.top/2017/03/30/hexo%E4%B8%BB%E9%A2%98%E5%92%8C%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E3%80%81%E6%89%93%E8%B5%8F%E3%80%81%E6%90%9C%E7%B4%A2%E3%80%81%E9%98%85%E8%AF%BB%E9%87%8F%E7%AD%89%E5%8A%9F%E8%83%BD/" target="_blank" rel="noopener">http://blog.rexking6.top/2017/03/30/hexo%E4%B8%BB%E9%A2%98%E5%92%8C%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E3%80%81%E6%89%93%E8%B5%8F%E3%80%81%E6%90%9C%E7%B4%A2%E3%80%81%E9%98%85%E8%AF%BB%E9%87%8F%E7%AD%89%E5%8A%9F%E8%83%BD/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;搭建个人博客：&lt;a href=&quot;https://www.jianshu.com/p/4eaddcbe4d12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.jianshu.com/p/4eaddcbe4d12&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>jupyter主题设置</title>
    <link href="http://pl741.github.io/2019/09/16/jupyter_%E4%B8%BB%E9%A2%98%E8%AE%BE%E7%BD%AE/"/>
    <id>http://pl741.github.io/2019/09/16/jupyter_主题设置/</id>
    <published>2019-09-16T05:12:47.831Z</published>
    <updated>2019-07-23T12:38:46.010Z</updated>
    
    <content type="html"><![CDATA[<h2 id="jupyter-主题设置"><a href="#jupyter-主题设置" class="headerlink" title="jupyter 主题设置"></a>jupyter 主题设置</h2><p>安装主题：pip install jupyterthemes</p><p>如果之前安装过可以更新一下：pip install –upgrade jupyterthemes</p><p>设置主题：蓝色主题——jt -t onedork -fs 95 -altp -tfs 11 -nfs 115 -cellw 88% -T</p><p>​                    黑色主题——jt -t monokai -f fira -fs 13 -cellw 90% -ofs 11 -dfs 11 -T -N</p><p>​                    部分参数：-f(字体)  -fs(字体大小) -cellw(占屏比或宽度)  </p><p>​                                      -ofs(输出段的字号)  -T(显示工具栏)  -N(显示自己主机名)</p><h4 id="Conda环境自由切换："><a href="#Conda环境自由切换：" class="headerlink" title="Conda环境自由切换："></a>Conda环境自由切换：</h4><p>​        看一下是否已经把 Anaconda 中创建的所有定制环境作为核心添加在了 Jupyter Notebook 中。这样我们就能简单地利用 Kernel 按钮切换环境。换核的时候不需要重启 notebook。</p><p>​        假设你的 Anaconda 环中有两个自定义的环境 my_NLP 和 gym。按照下面的步骤将这些添加到你的 Jupyter Notebook 中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">conda activate my_NLP</span><br><span class="line"># Install the IPython Kernel </span><br><span class="line">pip install ipykernel</span><br><span class="line"># Link your environment with Jupyter </span><br><span class="line"># Repeat steps for the other environment, gym</span><br><span class="line">python -m ipykernel install --user --name=my_NLP</span><br><span class="line">pip install ipykernel </span><br><span class="line">python -m ipykernel install --user --name=gym</span><br></pre></td></tr></table></figure><p>​        现在打开你的 Jupyter Notebook，找到 kernel 按钮下的 Change Kernel 选项，接下来就是见证奇迹的时刻：所有的核都被列举出来了，你可以通过简单地点击来激活一个服务核。</p><h4 id="其他功能："><a href="#其他功能：" class="headerlink" title="其他功能："></a>其他功能：</h4><p>​        安装 nbextensions for Jupyter Notebooks</p><p>​        安装 nbextensions 是很容易的，简单地遵循下面的步骤就行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Stop and exit your Jupyter Notebook server </span><br><span class="line"># Make sure you are in the base environment</span><br><span class="line">conda activate base</span><br><span class="line"># Install the nbextensions </span><br><span class="line">pip install jupyter_contrib_nbextensions</span><br><span class="line"># Install the necessary JS and CSS files </span><br><span class="line">jupyter contrib nbextension install --system</span><br></pre></td></tr></table></figure><p>​        启动 Jupyter notebook 服务，你可以在起始页看到第四个叫做 Nbextensions 的选项。点击这个选项，然后就可以看到极妙的功能集，这些都是你一直希望在 Jupyter Notebooks 中拥有的。</p><p>其中一些的简单介绍：</p><p>​          Table of Contents(2)：单击生成整个笔记本的目录，不同的 section 都有对应的超链接。</p><p>​         Scratchpad：在我看来绝对是最好的扩展了。这是一个你可以在里面做代码实验的独立空间，不会干扰笔记本中的其他部分。</p><p>​        Codefolding ：代码折叠，这个不需要做过多的解释。</p><p>​        Hide Input All：隐藏所有的代码单元，同时保持所有的输出和 markdown 单元可见。如果你要向非技术人员解释你的结果，那么这就会是一个很有用的功能。</p><p>​        Variable Inspector：将你从调试的忧伤中拯救出来，这与 Spyder IDE 中的变量检查窗口有些类似。</p><p>​        Spellchecker：对 markdown 单元中的内容进行拼写检查。</p><p>​        Zenmode：移除掉屏幕中杂乱无关的内容，以便你能够聚焦于重要的东西上，例如代码。</p><p>​        Snippets Menu：从 list comprehension 到 pandas 以及它们之间的所有常用代码片段的一个很酷的集合。这是最好的部分？你可以修改窗口的小部件来添加你自己的定制片段。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;jupyter-主题设置&quot;&gt;&lt;a href=&quot;#jupyter-主题设置&quot; class=&quot;headerlink&quot; title=&quot;jupyter 主题设置&quot;&gt;&lt;/a&gt;jupyter 主题设置&lt;/h2&gt;&lt;p&gt;安装主题：pip install jupyterthemes
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
