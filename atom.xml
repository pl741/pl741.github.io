<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>木木的博客</title>
  
  <subtitle>木木的博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://pl741.github.io/"/>
  <updated>2019-09-19T11:52:34.929Z</updated>
  <id>http://pl741.github.io/</id>
  
  <author>
    <name>木木</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>《Long Short Term Memory Networks for Anomaly Detection in Time Series》</title>
    <link href="http://pl741.github.io/2019/09/19/%E3%80%8ALong-Short-Term-Memory-Networks-for-Anomaly-Detection-in-Time-Series%E3%80%8B/"/>
    <id>http://pl741.github.io/2019/09/19/《Long-Short-Term-Memory-Networks-for-Anomaly-Detection-in-Time-Series》/</id>
    <published>2019-09-19T01:24:08.000Z</published>
    <updated>2019-09-19T11:52:34.929Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2015-56.pdf" target="_blank" rel="noopener">Long Short Term Memory Networks for Anomaly Dection in Time Series</a></p><h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>&emsp;&emsp;长短期记忆（LSTM）网络已被证明对于学习包含未知长度的长期模式的序列特别有用，因为它们能够维持长期记忆。在这样的网络中堆叠循环隐藏层还能够学习更高级别的时间特征，以便通过更稀疏的表示来更快地学习。在本文中，我们使用堆叠式LSTM（Stacked LSTM）网络进行时间序列中的异常检测。网络在非异常数据上进行训练，并用作多个时间步长的预测器。预测误差被建模为多变量高斯分布，用于评估异常行为的可能性。此方法的有效性在四个数据集上得到证实：ECG（心电图），航天飞机，电力需求和多传感器引擎数据集。</p><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h3><p>&emsp;&emsp;传统的过程监控技术在时间窗<sup>[1]</sup>上使用统计测量值，如累积和（CUSUM）和指数加权移动平均值（EWMA），以检测基础分布的变化。该时间窗口的长度通常需要预先确定，同时结果很大程度上取决于该参数。LSTM神经网络<sup>[2]</sup>通过采用乘法门来克服递归神经网络（RNN）所遇到的梯度消失问题。<u>该乘法门能保证常量错误一定从“内存单元”的内部状态通过</u>。输入$(IG)$，输出$(OG)$和遗忘$(FG)$门防止记忆内容被不相关的输入和输出扰动（参见$Fig.1(a)$），从而允许长期记忆存储。由于能够在序列中学习长期相关性，LSTM网络避免了对预先指定时间窗口的需要，并且能够精确地建模复杂的多变量序列。在本文中，我们通过堆叠式LSTM网络对时间序列的正常行为进行建模，我们可以准确地检测出与正常行为的偏差，而无需任何预先指定的上下文窗口或预处理。</p><img src="/2019/09/19/《Long-Short-Term-Memory-Networks-for-Anomaly-Detection-in-Time-Series》/1.png" title="$Fig.1:(a)$长短期记忆单元$(b)$堆叠结构"><p>&emsp;&emsp;已经表明，在网络中$Sigmoid$激活单元的堆叠循环隐藏层能更轻易地捕获时间序列的结构，并允许在不同的时间尺度处理时间序列<sup>[3]</sup>。使用分层时间处理技术进行异常检测的一个值得注意的例子是分层时间记忆（HTM）系统，它试图模仿新皮层中细胞，区域和水平的层次结构<sup>[4]</sup>。此外，像[5,6]这样的时间异常检测方法学习预测时间序列并使用预测误差来检测新颖性。然而，据我们所知，LSTM提供的记忆性功能尚未与循环分层处理层相结合，以用于预测时间序列并进行异常检测。</p><p>&emsp;&emsp;如[5]中所述，我们使用预测器建模正常行为，然后使用预测误差来识别异常行为。（这在现实世界的异常检测场景中特别有用，在这种场景中，正常行为的实例可能很多，但异常行为的实例很少见。）为了确保网络捕获序列的时间结构，我们预测未来的几个时间步骤。因此，序列中的每个点具有在过去的不同点处产生的多个对应的预测值，从而产生多个误差值。然后使用预测正常数据时的错误概率分布来获得在测试数据上正常行为的可能性。当控制变量（例如车辆加速器或制动器）也存在时，除了因变量之外，网络还用来预测控制变量。这迫使网络通过控制和相关传感器变量预测误差的联合分布来学习正常的使用模式：结果，当控制输入改变时已经捕获了明显的预测误差，并且不会有助于声明异常。</p><p>&emsp;&emsp;本文的其余部分安排如下：第2节描述了我们的方法。在第3节中，我们使用堆叠式LSTM方法（LSTM-AD）以及循环$Sigmoid$单元的堆叠RNN方法（RNN-AD），在四个真实世界数据集上呈现时间异常检测结果。第4节提供结论性意见。</p><h3 id="2-LSTM-AD：基于LSTM的异常检测"><a href="#2-LSTM-AD：基于LSTM的异常检测" class="headerlink" title="2. LSTM-AD：基于LSTM的异常检测"></a>2. LSTM-AD：基于LSTM的异常检测</h3><p>&emsp;&emsp;考虑一个时间序列$X=\left\{\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \dots, \mathbf{x}^{(n)}\right\}$，时间序列中的每个点$\mathbf{x}^{(t)} \in R^{m}$是一个$m$维的向量$\left\{x_{1}^{(t)}, x_{2}^{(t)}, \ldots, x_{m}^{(t)}\right\}$，，这些元素对应于输入变量。预测模型学习去预测输入变量$d$ $(s.t. 1 \leq d \leq m)$的接下来$l$个值。正常序列$(s)$被分为四组：正常训练集$(s_{N})$，正常验证集-1$(v_{N1})$，正常验证集-2$(v_{N2})$和正常测试集$(t_{N})$。异常序列$(s)$被分为两组：异常验证集$(v_{A})$和异常测试集$(t_{A})$。我们首先使用堆叠式LSTM网络学习一个预测模型，然后计算我们检测到异常的预测误差分布：</p><p>&emsp;&emsp;<strong>基于堆叠式LSTM的预测模型：</strong>我们考虑以下LSTM网络架构：对于$m$个维度中的每一个维度，我们都会对输入层放置一个单元，输出层有$d×l$个单元，使其满足对每一个维度的$l$个预测输出都有一个单元对应。隐藏层中的LSTM单元通过循环连接完全连接。我们基于如下方式堆叠LSTM层：较低层的LSTM隐藏层中的每个单元通过前馈连接完全连接到其上方的较高层的LSTM隐藏层中的每个单元（参见$Fig. 1(b)$）。使用$s_{N}$中的序列来学习预测模型。集合$v_{N1}$用于在学习网络权重时的提前停止。</p><p>&emsp;&emsp;<strong>基于预测误差分布的异常检测：</strong>在预测长度为$l$的情况下，对于$l&lt;t \leq n-1$，$\mathbf{x}^{(t)} \in X$中每个$d$维被预测$l$次。我们计算点$\mathbf{x}^{(t)}$的误差向量$ \mathbf e^{(t)}$,$\mathbf{e}^{(t)}=\left[e_{11}^{(t)}, \ldots, e_{1 l}^{(t)}, \ldots, e_{d 1}^{(t)}, \ldots, e_{d l}^{(t)}\right]$，其中$e_{ij}^{(t)}$表示$x_{i}^{(t)}$和其在$t-j$时间上的预测值之间的差。</p><p>&emsp;&emsp;在$s_{N}$上训练的预测模型用于计算验证和测试序列中每个点的误差向量。对误差向量进行建模以拟合多元高斯分布$\mathcal{N}=\mathcal{N}(\mu, \mathbf{\Sigma})$。观察误差向量$\mathbf e^{(t)}$的似然性$p^{(t)}$由$\mathcal{N}$在$\mathbf e^{(t)}$处的值给出（类似于使用基于卡尔曼滤波器的动态预测模型<sup>[5]</sup>的新颖性检测所使用的基于归一化新息平方$(NIS)$）。来自$v_{N1}$的点的误差向量用于使用最大似然估计来估计参数$μ$和$Σ$。如果$p^{(t)}&lt;τ$，则观察值$\mathbf x^{(t)}$被分类为“异常”，否则观察值被分类为“正常”。集合$v_{N2}$和$v_{A}$用于通过最大化$F_{β}-socre$来学习$τ$（其中异常点属于正类，而正常点属于负类）。</p><h3 id="3-实验"><a href="#3-实验" class="headerlink" title="3. 实验"></a>3. 实验</h3><p>&emsp;&emsp;我们在四个真实世界数据集上呈现LSTM-AD的结果，这些数据集在检测它们中的异常时具有不同的难度级别。在使用第2节中描述的验证集选择最大化$F_{0.1}-score$的网络架构以及和$τ$后，我们在表1中展示了采用LSTM-AD和RNN-AD两种方法的精度，召回率，$F_{0.1}-score$和架构。</p><h4 id="3-1-数据集"><a href="#3-1-数据集" class="headerlink" title="3.1 数据集"></a>3.1 数据集</h4><p>&emsp;&emsp;<em>心电图（ECGs)</em>：qtdb / sel102心电图数据集包含对应于心室前收缩的单个短期异常$(Fig.2 (a))$。由于ECG数据集只有一个异常，我们不计算该数据集的阈值和相应的$F_{0.1}-score$；我们只使用正常的ECG子序列学习预测模型，并计算剩余序列的误差向量的可能性。</p><p>&emsp;&emsp;<em>航天飞机Marotta阀门时间序列</em>：该数据集具有短时间段模式和长时间段模式，持续100个时间步长。数据集中存在三个异常区域在$Fig.2 (b)$中被标记为$a_{1}, a_{2}, a_{3}$。区域$a_{3}$是更容易辨别的异常，而区域$a_{1}$和$a_{2}$对应于在该方法下不易辨别的更微妙的异常。</p><p>&emsp;&emsp;<em>电力需求数据集</em>：电力消耗的正常行为是在每周中有五个峰值对应于五个工作日和两个低谷对应于周末。该数据集属于长期模式具有跨越数百个的时间步长。此外，此数据集有噪声，因为峰值不会在每条的同一时间出现。</p><p>&emsp;&emsp;<em>多传感器引擎数据</em>：该数据集具有来自12个不同的传感器：其中一个传感器是发动机的“控制”部件，其余的测量依赖如温度，扭矩等变量。我们使用对应于三个独立故障的序列来训练异常检测模型，并在三个不同的独立故障集上测量$F_{β}-score$。我们选择“控制”传感器和其他一个因变量作为要预测的值。</p><img src="/2019/09/19/《Long-Short-Term-Memory-Networks-for-Anomaly-Detection-in-Time-Series》/2.png" title="Fig.2: 样本序列（正常：绿色， 异常：蓝色）和相关似然$p$（红色）具有相同$S_{i}(i = 1,2,3)$的图具有相同的y轴"><h4 id="3-2-结果"><a href="#3-2-结果" class="headerlink" title="3.2 结果"></a>3.2 结果</h4><p>&emsp;&emsp;我们的实验结果的主要观察结果如下：</p><p>&emsp;&emsp;（i）在$Fig.2$ 中，对于所有数据集，异常区域中的似然值$p^{(t)}$显着低于正常区域。而且，$p^{(t)}$值在整个异常区域中不会保持低值。我们使用$β&lt;&lt; 1(0.1)$以便更加重视召回率的精确度：请注意，异常子序列中的所有点都具有“异常”标签，但实际上在这些中，也会存在许多“正常”行为点。因此，如果“异常”子序列中的很大一部分点被预测为异常就足够了。获得的$τ$值（$Fig.2. (a)- (f)$中的$p^{(t)}$图中的红色虚线）表明$F_{β}-score$（表1）是所考虑的数据集的合适度量。</p><p>&emsp;&emsp;（ii）对于所有数据集，发现阳性似然比（真阳性率/假阳性率）高（超过34.0）。高正似然比值表明在异常区域是异常的概率远高于在正常区域是异常的概率。</p><p>&emsp;&emsp;（iii）$Fig.2$ （f.1）和（f.2）显示了所选隐藏单元的激活，分别来自功率数据集的LSTM-L1（30个单元的低隐藏层）和LSTM-L2（20个单元的高隐藏层）各4个。在$Fig.2$ （f.2）中所示的最后激活序列中标记为$w_{1}$和$w_{2}$的子序列表示该隐藏单元激活在工作日期间高而在周末期间低。这些是由较高隐藏层学习的<em>high-level</em>特征的实例，其似乎以周为时间尺度操作。</p><p>&emsp;&emsp;（iv）如表1所示，对于没有任何长期时间依赖性的“ECG”和“引擎”数据集，LSTM-AD和RNN-AD的表现同样良好。另一方面，对于具有长期时间依赖性和短期依赖性的“航天飞机”和“电力需求”数据集，在$F_{0.1}-score$上LSTM-AD比RNN-AD分别显着提高了18％和30％。 </p><p>&emsp;&emsp;（v）“发动机”数据集故障前检测到的异常点的比例高于正常运行期间的异常点。这表明我们的方法可能对早期故障预测很有用。</p><img src="/2019/09/19/《Long-Short-Term-Memory-Networks-for-Anomaly-Detection-in-Time-Series》/3.png" title="Table 1: RNN和LSTM结构的精度，召回和$F_{0.1}-score$ 注意:（30-20）分别表示第一和第二隐藏层中的30和20个单位。"><h3 id="4-结论"><a href="#4-结论" class="headerlink" title="4.结论"></a>4.结论</h3><p>&emsp;&emsp;我们已经证明了（i）堆叠式LSTM网络能够在没有模式持续时间的先验知识的情况下学习更高级别的时间模式，因此（ii）堆叠的LSTM网络可能是建模正常时间序列行为的可行技术，然后可以用于检测异常。 我们的LSTM-AD方法在四个真实世界数据集上产生了有希望的结果，这些数据集涉及建模短期和长期时间依赖性。 与RNN-AD相比，LSTM-AD给出了更好或类似的结果，表明与基于RNN的模型相比，基于LSTM的预测模型可能更稳健，特别是当我们事先不知道正常行为是否涉及长期依赖性时。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] M. Basseville and I. V. Nikiforov. Detection of abrupt changes: theory and application. Prentice Hall, 1993.<br>[2] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation,9(8):1735–1780, 1997.<br>[3] M. Hermans and B. Schrauwen. Training and analysing deep recurrent neural networks. Advances in Neural Information Processing Systems 26, pages 190–198, 2013.<br>[4] D. George. How the brain might work: A hierarchical and temporal model for learning and recognition. PhD Thesis, Stanford University, 2008.<br>[5] P. Hayton et al. Static and dynamic novelty detection methods for jet engine health monitoring. Philosophical Transactions of the Royal Society of London, 365(1851):493–514, 2007.<br>[6] J. Ma and S. Perkins. Online novelty detection on temporal sequences. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 613–618. ACM, 2003. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2015-56.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Long Short Term Memory Netwo
      
    
    </summary>
    
    
      <category term="机器学习" scheme="http://pl741.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="时间序列异常检测" scheme="http://pl741.github.io/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>《Detecting Spacecraf Anomalies Using LSTMs and Nonparametric Dynamic Thresholding》</title>
    <link href="http://pl741.github.io/2019/09/16/%E3%80%8ADetecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding%E3%80%8B/"/>
    <id>http://pl741.github.io/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/</id>
    <published>2019-09-16T10:00:30.000Z</published>
    <updated>2019-10-09T03:11:31.363Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1802.04431.pdf" target="_blank" rel="noopener">Detecting Spacecraf Anomalies Using LSTMs and Nonparametric Dynamic Thresholding</a></p><h3 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h3><p>异常检测&emsp;神经网络&emsp;RNN&emsp;LSTM&emsp;时间序列</p><h3 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h3><h4 id="利用LSTMs进行遥测值预测"><a href="#利用LSTMs进行遥测值预测" class="headerlink" title="利用LSTMs进行遥测值预测"></a>利用LSTMs进行遥测值预测</h4><p>&emsp;&emsp;模型确定后，提供一种非参数、动态无监督的阈值方法来评估残差。</p><p>&emsp;&emsp;为每个单通道创建一个单独的模型，使用每个模型预测该通道的值。为每个通道单独建模还可以跟踪通道级别，实现航天器异常模式的细粒度检测。考虑时间序列$X=\left\{\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \ldots, \mathbf{x}^{(n)}\right\}$，其中时间序列中的每一步$\mathbf{x}^{(t)} \in R^{m}$为$m$维向量$\left\{x_{1}^{(t)}, x_{2}^{(t)}, \ldots, x_{m}^{(t)}\right\}$对应于输入向量，对于每个点$\mathbf{x}^{(t)}$，序列长度$l_s$决定输入模型进行预测的点的数量，预测长度$l_p$决定预测的步长，预测维度$d$的范围为$1 \leq d \leq m$。要预测单个通道的遥测值则$d=1$，同时使用$l_p=1$限制每个步骤$t$的预测数量，以减少运行时间。在每个步骤$t$为实际遥测值生成单个标量预测值$\hat{y}^{(t)}$。在本次实验中输入到LSTM中的$x^{(t)}$包括给定信道的先验遥测值和发送到航天器的编码命令信息。发出命令的模块和发送或接收命令的模块的组合是一个 one-hot 编码的模块，插入到每个步骤$t$中。</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/1.png" title="图1. 每个时间步长$t$预测所用输入矩阵的可视化表示。将当前预测误差与过去预测误差进行比较，以确定是否异常"><h4 id="动态误差阈值"><a href="#动态误差阈值" class="headerlink" title="动态误差阈值"></a>动态误差阈值</h4><p>&emsp;&emsp;本文提出一种方法，可以在不做对过去平滑误差分布做高斯假设的情况下有效地标识极值。每一步$t$产生一个预测值$\hat{y}^{(t)}$，预测误差$e^{(t)}=\left|y^{(t)}-\hat{y}^{(t)}\right|$，其中$y^{(t)}=x_{i}^{(t+1)}$，其中$i$对应于真实遥测值得维度，将每个误差$e^{(t)}$添加到一维误差$e$ 向量中，</p><script type="math/tex; mode=display">\mathbf{e}=\left[e^{(t-h)}, \ldots, e^{\left(t-l_{s}\right)}, \ldots, e^{(t-1)}, e^{(t)}\right]</script><p>其中$h$表示用于评估当前误差的历史误差值的数量，然后对误差集$\mathbf e$进行平滑以抑制LSTM预测中的尖锐误差值，这些尖锐误差会影响预测结果，即使在正常情况下，也会出现误差值的急剧峰值。本文使用指数加权平均（EWMA）来产生平滑误差$\mathbf{e}_{s}=\left[e_{s}^{(t-h)}, \ldots, e_{s}^{(t-l s)}, \ldots, e_{s}^{(t-1)}, e_{s}^{(t)}\right]$。为评估这些值是否为正常值，本文将为平滑预测误差设置一个阈值，将阈值以上的平滑预测误差值对应的值分类为异常。</p><p>&emsp;&emsp;<strong>阈值计算和异常评分</strong>：本文提出一种无监督的异常阈值计算方法，可以在低开销、不使用标记数据或误差统计假设的情况下实现高效的阈值计算。阈值$\epsilon$从以下集合中选出：</p><script type="math/tex; mode=display">\boldsymbol{\epsilon}=\mu\left(\mathbf{e}_{s}\right)+\mathbf{z} \sigma\left(\mathbf{e}_{s}\right)</script><p>其中$\epsilon$取决于：</p><script type="math/tex; mode=display">\epsilon=\arg \max (\boldsymbol{\epsilon})=\frac{\Delta \mu\left(\mathbf{e}_{s}\right) / \mu\left(\mathbf{e}_{s}\right)+\Delta \sigma\left(\mathbf{e}_{s}\right) / \sigma\left(\mathbf{e}_{s}\right)}{\left|\mathbf{e}_{a}\right|+\left|\mathbf{E}_{s e q}\right|^{2}}</script><p>其中：</p><script type="math/tex; mode=display">\begin{array}{l}{\Delta \mu\left(\mathbf{e}_{s}\right)=\mu\left(\mathbf{e}_{s}\right)-\mu\left(\left\{e_{s} \in \mathbf{e}_{s} | e_{s}<\epsilon\right\}\right)} \\ {\Delta \sigma\left(\mathbf{e}_{s}\right)=\sigma\left(\mathbf{e}_{s}\right)-\sigma\left(\left\{e_{s} \in \mathbf{e}_{s} | e_{s}<\epsilon\right\}\right)} \\ {\mathbf{e}_{a}=\left\{e_{s} \in \mathbf{e}_{s} | e_{s}>\epsilon\right\}} \\ {\mathbf{E}_{s e q}=\text { continuous sequences of } e_{a} \in \mathbf{e}_{a}}\end{array}</script><p>使用$z \in \mathbf{z}$来确定$\epsilon$的评估值，其中$\mathbf z$是一个有序正值集，表示标准差大于$\mu\left(\mathbf{e}_{s}\right)$的数量。$\mathbf z$的值取决于上下文，但根据实验结果，$2 - 10$之间的范围可以很好的工作。$z &lt;2$的值通常会导致过多的假阳性。一旦确定了$\arg \max (\boldsymbol{\epsilon})$，每个得到的平滑错误序列$\mathbf{e}_{s e q} \in \mathbf{E}_{s e q}$都会得到一个异常分数$s$，用来表示异常的严重程度：</p><script type="math/tex; mode=display">s^{(i)}=\frac{\max \left(\mathbf{e}_{s e q}^{(i)}\right)-\arg \max (\boldsymbol{\epsilon})}{\mu\left(\mathbf{e}_{s}\right)+\sigma\left(\mathbf{e}_{s}\right)}</script><p>也就是说，如果找到一个阈值，去掉超过它的所有值，平滑误差$\mathbf e_{s}$的均值和标准差都会下降最大的百分比。该函数还惩罚具有最大异常值$\left(\left|\mathbf{e}_{a}\right|\right)$和序列$\left(\left|\mathbf{E}_{s e q}\right|\right)$以防止过度贪心行为。然后根据每个异常误差序列到所选阈值的距离，给出平滑误差最大值的归一化分数。</p><h4 id="减少误报"><a href="#减少误报" class="headerlink" title="减少误报"></a>减少误报</h4><p>&emsp;&emsp;<strong>修剪异常</strong>：基于预测的异常检测方法的精度很大程度上取决于用于设置阈值和判定当前预测误差的历史数据量$(h)$。为了减少误报、限制内存和计算成本，我们引入了一个剪枝过程，创建一个新集合$\mathbf{e}_{m a x}$，包含按照降序排序的所有$\mathbf{e}_{s e q}$的$\max \left(\mathbf{e}_{s e q}\right)$。同时在$\mathbf e_{max}$的末尾添加一个非异常$\max \left(\left\{e_{s} \in \mathbf{e}_{s} \in \mathbf{E}_{s e q} | e_{s} \in \mathbf{e}_{a}\right\}\right)$的最大平滑误差。之后以增量的方式逐步执行序列，计算每一步的减少百分比$d^{(i)}=\left(e_{\max }^{(i-1)}-e_{\max }^{(i)}\right) / e_{\max }^{(i-1)}$，其中$i \in\left\{1,2, \ldots,\left(\left|\mathbf{E}_{s e q}\right|+1\right)\right\}$。如果在某个步骤$i$中，$d^{(i)}$超过了最小百分比降幅$p$，则所有$e_{m a x}^{(j)} \in \mathbf{e}_{m a x} | j&lt;i$及其对应的异常序列均为异常。如果$d^{(i)}$没有满足最小减少量$p$，对于所有后续平滑的误差序列$d^{(i)}, d^{(i+1)}, \ldots, d^{\left(i+\left|\mathbf{E}_{s e q}\right|+1\right)}$都将被重新分类为正常误差。这种剪枝有助于确保异常序列不是流中常规噪声的结果，并且可通过阈值处理来初始识别异常序列。将评估仅限于少数潜在异常序列中的最大误差比没有阈值处理所需的大量值 - 值比较要有效得多。</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/2.png" title="图2. 展示异常修剪过程的例子"><p>&emsp;&emsp;在这种情况下，$\mathbf{e}_{m a x}=[0.01396,0.01072,0.00994]$，最小下降百分比 $p=0.1$。从异常$2$到异常$1$的下降幅度为 $d^{(1)}=0.23&gt;p$，该序列保留为异常分类。从异常$1$到下一个最高平滑误差$\left(e_{s}=0.0099 \right)$的下降幅度为 $d^{(2)}=.07&lt;p$，因此这个序列被重新分类为正常序列。</p><p>&emsp;&emsp;<strong>学习历史数据</strong>：一旦收集到少量异常历史纪录或标记数据，就可以使用这种学习策略来抑制假阳性。基于相似度$s$的异常通常不会在同一频道内频繁重复出现的假设，可以设置最小分数$s_{min}$，以便在$\boldsymbol{s}&lt;\boldsymbol{s}_{\min }$时，将未来的异常重新分类为正常。最低分数只适用于系统产生异常率超过某一比率的数据通道，并为所有这些通道单独设置$s_{min}$。可以使用通道的先验异常得分来设置适当的$s_{min}$，具体取决于精确度和召回率之间的期望平衡。此外，如果异常检测系统有一种机制，用户可以通过该机制为异常提供标签，那么这些标签还可以用于为给定流设置$s_{min}$。例如，如果一个流或通道有多个合并的假阳性异常，那么$s_{min}$可以设置在这些假阳性异常分数的上界附近。</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/3.png" title="图3 包含上下文异常的遥测流命令信息编码"><p>&emsp;&emsp;这种异常不太可能使用基于限制或距离的方法进行识别。使用已编码的命令信息和信道的先前遥测值生成下一个时间步骤的预测，并产生误差。在这个例子中，一步预测和实际遥测值非常接近，如顶部时间序列所示。利用非参数阈值化方法设置误差阈值，得到标记异常区域内的两个预测异常序列，一个为假阳性，一个为真阳性。假阳性表明需要对序列进行修剪，如果该序列相对接近阈值以下的值，则将该序列重新分类为正常序列（参见图2）。</p><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>&emsp;&emsp;我们将异常分为两类：点异常和上下文异常，以区分可能由适当设置的警报或忽略时间信息的基于距离的方法（点异常）识别的异常和需要更复杂的方法（如LSTMs或分层时间记忆（HTM）方法）来检测（上下文异常）的异常。这个特征是从前面提到的三个类别中改编而来的——点异常、上下文异常、集合异常。由于上下文异常和集合异常都需要时间上下文，并且比较难以检测，因此它们都被合并到上下文类别中。</p><p>&emsp;&emsp;<strong>设置：</strong>对于主要发生在时间$t_{a}$包含一个或多个异常序列的每个唯一数据流，我们评估从$t_{s}=t_{a}-3 d$到$t_{f}=t_{a}+2 d$ 时间帧之间的所有遥测值， 其中$d$表示天。使用从$t_{s_{\text {train}}}=t_{s}-2 d$到$t_{f_{\text {train}}}=t_{s}$的值和命令数据为每个唯一流训练模型。如果在这些时间范围内没有足够的数据，则增加额外的天数。5天的异常周期被选择用来平衡两个目标：精度和计算成本。预测异常区域略微扩大，以便将扩展后重叠或邻近的异常区域合并为一个区域，来解释多个异常区域代表一个时间的情况。根据系统识别出的最后一组预测异常序列，对每个标记的遥测异常序列$x_{a} \in \mathbf{x}_{a}$按照下面规则进行评估：</p><p>&emsp;&emsp;（1）真阳性：</p><script type="math/tex; mode=display">\left|e_{a}^{(t)} \in e_{s e q} \in \mathbf{e}_{s e q} : x_{i}^{(t)} \in x_{a}\right|>0</script><p>&emsp;&emsp;对于任意的$x_{a} \in \mathbf{x}_{a}$，换句话说，预测异常序列的任何一部分都属于任何真实标记序列，则结果为真阳性。即使许多预测序列的一部分属于标记序列也仅纪录一个真阳性。</p><p>&emsp;&emsp;（2）如果没有预测序列与阳性标记序列重叠，标记为假阴性。</p><p>&emsp;&emsp;（3）所有没有与标记异常区域重叠的预测序列，标记为假阳性。</p><p>&emsp;&emsp;为简单起见，我们不会根据检测到异常的早期程度或误报与标记区域之间的距离进行评分调整。</p><p>&emsp;&emsp;<strong>批处理：</strong>遥测数据被聚合到一分钟窗口中，按照SMAP和当前系统实现的下行计划，以70分钟/组进行评估。使用$h=2100$计算每70分钟批处理的值，其中$h$是用于计算错误阈值和评估当前批处理的先前值的数量。该系统还非常适合以实时流式方式处理值。</p><p>&emsp;&emsp;<strong>模型参数和评估：</strong>在实验中所有模型使用相同的架构和参数：</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/4.png"><p>&emsp;&emsp;每个模型都是只含有两层隐藏层和80个（/层）单元的浅层模型。我们发现这种结构能够提供足够的能力来很好的预测单个通道，增加额外的能力在增加模型大小和训练时间的同时对提供预测效益没有任何用处。所有通道不一定都需要这么大的容量，未来的改进可能包括根据信道复杂度自动选择合适的模型容量。类似地，序列长度$l_{s}=250$提供了性能和训练时间之间的平衡。SMAP和MSL在输入维度上的差异是由于每个任务都有不同的命令模块集。在模型训练过程中，早期停止被用来防止过度拟合，并不是所有的模型都经过了完整35次迭代的训练。预测生成后，采用3.2节的方法计算平滑误差的异常阈值，其中$\mathbf{z}=\{2.5,3.0,3.5, \ldots, 10.0\}$，并且后续异常值之间的最小百分比只差$p=0.13$。参数$p$是控制精确度和召回率的重要标准，当标签可用时可推断出一个适当的值。在我们的设置中，在$0.05&lt;p&lt;0.20$达到了合理的结果。</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/5.png" title="图4 参数方法和本文提出的方法（标记为“非参数”）在不同参数设置下的总体精度和召回结果的比较的图。"><p>&emsp;&emsp;<strong>参数阈值比较：</strong>使用原始的LSTM进行误差预测，我们还使用参数误差评估方法生成异常，该方法与Numenta异常基准的最精确模型相协调。这种方法递增地处理原始误差-在每个步骤$t$，将历史误差的窗口$W$建模为正态分布，并且在每个步骤$t$更新均值$μ_{w}$和方差$σ_{W}^{2}$。我们设置$W$的长度为$l_{w}=h=2100$，并对两种方法使用相同的预测误差集。然后计算预测误差长度$l_{short}$的短期平均值$μ_{s}$，其平滑效果与第3.2节中的EWMA平滑相似。然后使用尾概率$Q$来定义异常$L$的可能性:</p><script type="math/tex; mode=display">L=1-Q\left(\frac{\mu_{s}-\mu_{W}}{\sigma_{W}^{2}}\right)</script><p>如果$L \geq 1-\epsilon_{n o r m}$的值为分类为异常。在下一节中，使用$l_{short}=10$和$\epsilon_{n o r m}=\{0.01,0.0001\}$生成的结果与3.2节中的方法进行比较。</p><h3 id="复现实验"><a href="#复现实验" class="headerlink" title="复现实验"></a>复现实验</h3><p>&emsp;&emsp;GitHub地址：<a href="https://github.com/khundman/telemanom" target="_blank" rel="noopener">https://github.com/khundman/telemanom</a></p><p>&emsp;&emsp;<strong>遥测数据：包含两个分支</strong>  </p><p>&emsp;&emsp;&emsp;1.  master：包含标记异常的数据并用于复现KDD论文中的实验<br>&emsp;&emsp;&emsp;2.  no-labels：未标记的数据（一组时间序列流）</p><p>&emsp;&emsp;<strong>开始</strong>：</p><p>&emsp;&emsp;&emsp;克隆仓库——<code>git clone https://github.com/khundman/telemanom.git &amp;&amp; cd telemanom</code></p><p>&emsp;&emsp;&emsp;Curl和Unzip数据——<code>curl -O https://s3-us-west-2.amazonaws.com/telemanom/data.zip &amp;&amp; unzip data.zip &amp;&amp; rm data.zip</code></p><p>&emsp;&emsp;&emsp;使用Python 3.6+安装依赖项——<code>pip install -r requirements.txt</code></p><p>&emsp;&emsp;&emsp;在<code>config.yaml</code>文件中配置系统/模型参数：<br>&emsp;&emsp;&emsp;&emsp;&emsp;<code>train:</code> 如果是<code>True</code>，将为每个输入流训练一个新模型；如果是 <code>False</code> ，将加载现有的训练模型并用于生成预测。<br>&emsp;&emsp;&emsp;&emsp;&emsp;<code>predict:</code> 如果是<code>Ture</code>，使用模型生成新的预测；如果是<code>False</code>，请在评估中使用现有的已保存预测（用于调整错误阈值并跳过先前的处理步骤）<br>&emsp;&emsp;&emsp;&emsp;&emsp;<code>l_s:</code> 250 确定在每个时间步$t$上输入到模型的先前时间步数（用于生成预测）</p><p>&emsp;&emsp;&emsp;开始实验——<code>python run.py</code></p><p>&emsp;&emsp;&emsp;利用<code>Jupyter notebook</code>来进行结果评估并比较不同参数的运行结果在<code>results/</code>下提供。启动notebook——<code>jupyter notebook results/result-viewer.ipynb</code><br>&emsp;&emsp;&emsp;Plotly用于生成交互式内联图，例如：</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/6.png"><p>&emsp;&emsp;<strong>数据</strong>：</p><p>&emsp;&emsp;&emsp;&emsp;<strong>使用你自己的数据</strong></p><p>&emsp;&emsp;&emsp;首先划分数据集为训练数据集和测试数据集并分别放在<code>data/train/</code>和<code>data/test/</code>文件夹下。对于训练集和测试集为每个通道或流生成形状为<code>(n_timesteps, n_inputs)</code>的一个<code>.npy</code>文件。每个文件名应该具有唯一的名称或ID。在测试数据中预测的遥测值必须是输入中的第一个特征。</p><p>&emsp;&emsp;&emsp;例如，<code>T-1</code>通道应该具有被命名为<code>T-1.npy</code>的训练集/测试集，形状类似于<code>(4900, 61)</code>和<code>(3925, 61)</code>，其中输入维度大小是<code>(61)</code>。实际遥测值应沿第一维<code>(4900, 1)</code>和<code>(3925, 1)</code>。</p><p>&emsp;&emsp;&emsp;&emsp;<strong>原始数据</strong></p><p>&emsp;&emsp;&emsp;可供下载的原始数据代表了来自SMAP卫星和MSL卫星真实的航天器遥测数据和异常。所有数据都已在时间上匿名化，并且所有遥测值都根据测试集中的最小值/最大值在<code>(-1,1)</code>之间预先缩放。通道ID也被匿名化，但是第一个字母表示出通道的类型（<code>P</code>=功率，<code>R</code>=辐射）。模型输入数据还包括有关特定航天器模块在给定时间窗口内发送或接收的命令的<code>one-hot</code>编码信息。模型输入数据还包括有关特定航天器模块在给定时间窗口内发送或接收的命令的一键编码信息。数据中不包含与命令的时间或特性有关的识别信息。 例如：</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/3.png"><p>&emsp;&emsp;&emsp;此数据还包括使用<code>config.yaml</code>中的默认设置生成的预分割测试和训练数据，预训练模型，预测和平滑错误。当熟悉仓库时，可通过运行<code>result-viewer.ipynb</code>来可视化结果。数据对于隔离系统的各个部分也很有用。例如，如果你希望在不训练新模型的情况下看到阈值参数更改的影响，可以在<code>config.yaml</code>中将<code>Train</code>和<code>Predict</code>设置为<code>False</code>，以使用从之前模型生成的预测。</p><p>&emsp;&emsp;<strong>异常标签和元数据</strong>：</p><p>&emsp;&emsp;&emsp;异常标签和元数据可在<code>labeled_anomalies.csv</code>中使用，包括：</p><p>&emsp;&emsp;&emsp; <code>channel_id</code>: 匿名的频道ID———首字母代表频道的性质（<code>P</code>=功率，<code>R</code>=辐射）。<br>&emsp;&emsp;&emsp; <code>spacecraft</code>: 产生遥测流的航天器<br>&emsp;&emsp;&emsp; <code>anomaly_sequences</code>: 流中真实异常开始和结束的索引<br>&emsp;&emsp;&emsp; <code>class</code>: 异常的类别<br>&emsp;&emsp;&emsp; <code>num values</code>: 每个流中的遥测值数量</p><p>&emsp;&emsp;&emsp;要提供自己的标签，请使用<code>labeled_anomalies.csv</code>文件作为模板。  唯一需要的字段/列是<code>channel_id</code>和<code>anomaly_sequences</code>。 <code>anomaly_sequences</code>是列表中的一列，其中包含通道的测试数据集中异常区域的开始和结束索引。</p><p>&emsp;&emsp;<strong>数据集和性能统计</strong>：</p><p>&emsp;&emsp;&emsp;&emsp;数据：</p><img src="/2019/09/16/《Detecting-Spacecraf-Anomalies-Using-LSTMs-and-Nonparametric-Dynamic-Thresholding》/7.png"><p>&emsp;&emsp;&emsp;&emsp;性能统计：</p><p>&emsp;&emsp;<strong>处理</strong>：</p><p>&emsp;&emsp;每次启动系统时，唯一的日期时间ID（例如2018-05-17_16.28.00）将用于创建以下内容:</p><p>&emsp;&emsp;<code>results</code>文件：（在<code>results /</code>中），该文件扩展了<code>labeled_anomalies.csv</code>包括已识别的异常序列和相关信息。</p><p>&emsp;&emsp;<code>data subdirectory</code>: 包含用于每个通道的已创建模型，预测和平滑错误的数据文件。 还创建了一个名为<code>params.log</code>的文件，其中包含参数设置和处理期间的日志记录输出。</p><p>&emsp;&emsp;如前所述，jupyter notebook的<code>results / result-viewer.ipynb</code>可用于可视化每个流的结果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1802.04431.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Detecting Spacecraf Anomalies Using LSTMs and Nonparametric
      
    
    </summary>
    
    
      <category term="机器学习" scheme="http://pl741.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="时间序列异常检测" scheme="http://pl741.github.io/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>使用链接</title>
    <link href="http://pl741.github.io/2019/09/16/%E9%93%BE%E6%8E%A5/"/>
    <id>http://pl741.github.io/2019/09/16/链接/</id>
    <published>2019-09-16T07:38:06.000Z</published>
    <updated>2019-09-16T10:09:59.426Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/4eaddcbe4d12" target="_blank" rel="noopener">搭建个人博客</a></p><p><a href="http://blog.rexking6.top/2017/03/30/hexo%E4%B8%BB%E9%A2%98%E5%92%8C%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E3%80%81%E6%89%93%E8%B5%8F%E3%80%81%E6%90%9C%E7%B4%A2%E3%80%81%E9%98%85%E8%AF%BB%E9%87%8F%E7%AD%89%E5%8A%9F%E8%83%BD/" target="_blank" rel="noopener">博客个性化设置</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/4eaddcbe4d12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;搭建个人博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.rexking6.top/2017/
      
    
    </summary>
    
    
    
      <category term="配置" scheme="http://pl741.github.io/tags/%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>jupyter主题设置</title>
    <link href="http://pl741.github.io/2019/09/16/jupyter_%E4%B8%BB%E9%A2%98%E8%AE%BE%E7%BD%AE/"/>
    <id>http://pl741.github.io/2019/09/16/jupyter_主题设置/</id>
    <published>2019-09-16T05:38:06.000Z</published>
    <updated>2019-09-16T09:57:34.711Z</updated>
    
    <content type="html"><![CDATA[<h2 id="jupyter-主题设置"><a href="#jupyter-主题设置" class="headerlink" title="jupyter 主题设置"></a>jupyter 主题设置</h2><p>安装主题：pip install jupyterthemes</p><p>如果之前安装过可以更新一下：pip install —upgrade jupyterthemes</p><p>设置主题：蓝色主题——jt -t onedork -fs 95 -altp -tfs 11 -nfs 115 -cellw 88% -T</p><p>​                    黑色主题——jt -t monokai -f fira -fs 13 -cellw 90% -ofs 11 -dfs 11 -T -N</p><p>​                    部分参数：-f(字体)  -fs(字体大小) -cellw(占屏比或宽度)  </p><p>​                                      -ofs(输出段的字号)  -T(显示工具栏)  -N(显示自己主机名)</p><h4 id="Conda环境自由切换："><a href="#Conda环境自由切换：" class="headerlink" title="Conda环境自由切换："></a>Conda环境自由切换：</h4><p>​        看一下是否已经把 Anaconda 中创建的所有定制环境作为核心添加在了 Jupyter Notebook 中。这样我们就能简单地利用 Kernel 按钮切换环境。换核的时候不需要重启 notebook。</p><p>​        假设你的 Anaconda 环中有两个自定义的环境 my_NLP 和 gym。按照下面的步骤将这些添加到你的 Jupyter Notebook 中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">conda activate my_NLP</span><br><span class="line"># Install the IPython Kernel </span><br><span class="line">pip install ipykernel</span><br><span class="line"># Link your environment with Jupyter </span><br><span class="line"># Repeat steps for the other environment, gym</span><br><span class="line">python -m ipykernel install --user --name=my_NLP</span><br><span class="line">pip install ipykernel </span><br><span class="line">python -m ipykernel install --user --name=gym</span><br></pre></td></tr></table></figure><p>​        现在打开你的 Jupyter Notebook，找到 kernel 按钮下的 Change Kernel 选项，接下来就是见证奇迹的时刻：所有的核都被列举出来了，你可以通过简单地点击来激活一个服务核。</p><h4 id="其他功能："><a href="#其他功能：" class="headerlink" title="其他功能："></a>其他功能：</h4><p>​        安装 nbextensions for Jupyter Notebooks</p><p>​        安装 nbextensions 是很容易的，简单地遵循下面的步骤就行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Stop and exit your Jupyter Notebook server </span><br><span class="line"># Make sure you are in the base environment</span><br><span class="line">conda activate base</span><br><span class="line"># Install the nbextensions </span><br><span class="line">pip install jupyter_contrib_nbextensions</span><br><span class="line"># Install the necessary JS and CSS files </span><br><span class="line">jupyter contrib nbextension install --system</span><br></pre></td></tr></table></figure><p>​        启动 Jupyter notebook 服务，你可以在起始页看到第四个叫做 Nbextensions 的选项。点击这个选项，然后就可以看到极妙的功能集，这些都是你一直希望在 Jupyter Notebooks 中拥有的。</p><p>其中一些的简单介绍：</p><p>​          Table of Contents(2)：单击生成整个笔记本的目录，不同的 section 都有对应的超链接。</p><p>​         Scratchpad：在我看来绝对是最好的扩展了。这是一个你可以在里面做代码实验的独立空间，不会干扰笔记本中的其他部分。</p><p>​        Codefolding ：代码折叠，这个不需要做过多的解释。</p><p>​        Hide Input All：隐藏所有的代码单元，同时保持所有的输出和 markdown 单元可见。如果你要向非技术人员解释你的结果，那么这就会是一个很有用的功能。</p><p>​        Variable Inspector：将你从调试的忧伤中拯救出来，这与 Spyder IDE 中的变量检查窗口有些类似。</p><p>​        Spellchecker：对 markdown 单元中的内容进行拼写检查。</p><p>​        Zenmode：移除掉屏幕中杂乱无关的内容，以便你能够聚焦于重要的东西上，例如代码。</p><p>​        Snippets Menu：从 list comprehension 到 pandas 以及它们之间的所有常用代码片段的一个很酷的集合。这是最好的部分？你可以修改窗口的小部件来添加你自己的定制片段。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;jupyter-主题设置&quot;&gt;&lt;a href=&quot;#jupyter-主题设置&quot; class=&quot;headerlink&quot; title=&quot;jupyter 主题设置&quot;&gt;&lt;/a&gt;jupyter 主题设置&lt;/h2&gt;&lt;p&gt;安装主题：pip install jupyterthemes
      
    
    </summary>
    
    
    
      <category term="配置" scheme="http://pl741.github.io/tags/%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>机器学习评价标准</title>
    <link href="http://pl741.github.io/2019/09/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86/"/>
    <id>http://pl741.github.io/2019/09/16/机器学习评价标准/</id>
    <published>2019-09-16T05:38:06.000Z</published>
    <updated>2019-09-16T07:24:19.337Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本内容"><a href="#基本内容" class="headerlink" title="基本内容"></a>基本内容</h1><p><strong>True真&emsp; False假&emsp;Positive正&emsp;Negative负</strong></p><p>&emsp;&emsp;异常检测中，P和N一般是针对预测来说的，Positive正类指的是你更关心的那一类！即“异常”，P指预测为正类，即预测为异常。T和F针对预测与真实情况的比较， True指正确匹配，F指错误匹配。</p><div class="table-container"><table><thead><tr><th></th><th style="text-align:center">实际正例</th><th style="text-align:center">实际负例</th><th style="text-align:center"></th></tr></thead><tbody><tr><td>预测正例P</td><td style="text-align:center">TP</td><td style="text-align:center">FP</td><td style="text-align:center">所有预测为正的个数TP+FP</td></tr><tr><td>预测负例N</td><td style="text-align:center">FN</td><td style="text-align:center">TN</td><td style="text-align:center">所有预测为负的个数FN+TN</td></tr><tr><td></td><td style="text-align:center">所有实际正例的个数TP+FN</td><td style="text-align:center">所有实际负例的个数FP+TN</td></tr></tbody></table></div><img src="/2019/09/16/机器学习评价标准/72.png"><ul><li><p>TPR：真正类率，代表预测是异常实际也是异常的样本数，占实际总异常数的比例——值越大 性能越好</p></li><li><p>FPR：假正类率，代表预测是异常但实际是正常的样本数，占实际正常总数的比例——值越小 性能越好</p></li><li><p>R：召回率，意义同TPR——值越大 性能越好</p></li><li><p>P：精确率Precision，代表预测是异常实际也是异常的样本数，占预测是异常的总数的比例——值越大 性能越好</p></li><li><p>F：P和R的加权调和平均，常用的是F1值——值越大 性能越好</p></li><li><p>A：正确率Accuracy，与精确率的区别是，不仅考虑异常类也考虑正常类，即所有匹配样本数，占所有样本的比例——值越大 性能越好</p></li></ul><p>另外还有两个，分别为：虚警率和漏警率</p><ul><li>虚警率（<strong>False alarm</strong>）表示负类样本被分为正类样本在所有负类样本中的比例</li></ul><img src="/2019/09/16/机器学习评价标准/71.png"><ul><li>漏警率表示（漏警率表示（Missing alarm）表示正类样本被分为负类样本在所有正类样本中的比例Missing alarm）表示正类样本被分为负类样本在所有正类样本中的比例</li></ul><img src="/2019/09/16/机器学习评价标准/70.png"><h1 id="Tensorflow实现"><a href="#Tensorflow实现" class="headerlink" title="Tensorflow实现"></a>Tensorflow实现</h1><p><strong>&emsp;损失值：</strong><br>    tf.nn.softmax_cross_entropy_with_logits(logits, labels, name=None)<br><strong>&emsp;参数解析：</strong><br>&emsp; logits:神经网络最后一层的输出，如果有batch，大小为[batch_size, n_classes]<br>&emsp; labels:实际标签，大小同上</p><p><strong>&emsp;执行过程：</strong><br>&emsp;&emsp;先对网络最后一层的输出做一个softmax，通常是求取输出属于某一类的概率，对于单样本而言，输出就是一个num_classes大小的向量。</p><img src="/2019/09/16/机器学习评价标准/73.png"><p>&emsp;然后将softmax的输出向量与样本的实际标签做一个交叉熵。</p><img src="/2019/09/16/机器学习评价标准/74.png"><p>&emsp;其中 y’ 指代实际的标签中第i个的值（用mnist数据举例，如果是3，那么标签是[0，0，0，1，0，0，0，0，0，0]，除了第4个值为1，其他全为0）; y就是softmax的输出向量[Y1，Y2,Y3…]中，第i个元素的值</p><p>&emsp;&emsp;显而易见，预测越准确，结果的值越小（别忘了前面还有负号），最后求一个平均，得到我们想要的loss</p><p>&emsp;&emsp;注意！！！这个函数的返回值并不是一个数，而是一个向量，如果要求交叉熵，我们要再做一步tf.reduce_sum操作,就是对向量里面所有元素求和，最后才得到H(y)，如果求loss，则要做一步tf.reduce_mean操作，对向量求均值！</p><pre><code>tf.reduce_mean(input_tensor, axis=None,keep_dims=False,name=None,               reduction_indices=None)</code></pre><h4 id="参数解析"><a href="#参数解析" class="headerlink" title="参数解析"></a>参数解析</h4><ul><li>&emsp; 第一个参数input_tensor： 输入的待降维的tensor;</li><li>&emsp; 第二个参数axis： 指定的轴，如果不指定，则计算所有元素的均值;</li><li>&emsp; 第三个参数keep_dims：是否降维度，设置为True，输出的结果保持输入tensor的形状，设置为False，输出结果会降低维度;</li><li>&emsp; 第四个参数name： 操作的名称;</li><li>&emsp; 第五个参数 reduction_indices：在以前版本中用来指定轴，已弃用;</li></ul><p>&emsp;predict是预测结果，也就是神经网络的输出，real是真实的标签，sess就是tensorflow当前的会话，feed_dict是需要喂的数据。</p><p>&emsp;tf.equal(A, B)是对比这两个矩阵或者向量的相等的元素，如果是相等的那就返回True，反正返回False，返回的值的矩阵维度和A是一样的。</p><p>&emsp;tf.cast()函数的作用是执行 tensorflow 中张量数据类型转换，<br>    tf.cast(x, dtype, name=None)</p><h4 id="参数解析-1"><a href="#参数解析-1" class="headerlink" title="参数解析"></a>参数解析</h4><ul><li>&emsp;第一个参数 x:   待转换的数据（张量）</li><li>&emsp;第二个参数 dtype： 目标数据类型</li><li>&emsp;第三个参数 name： 可选参数，定义操作的名称</li></ul><p>&emsp;tf.loical_and()将数值变成逻辑值<br>    tf.logical_and(x, y, name=None)</p><p>&emsp;tf.argmax()返回值是是数值最大值的索引位置，如果最大值位置相同，则分类正确，反之则分类错误<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">predictions = tf.argmax(predict, <span class="number">1</span>)</span><br><span class="line">actuals = tf.argmax(real, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将上述获得的变量设置成元素为0或者为1的矩阵</span></span><br><span class="line">ones_like_actuals = tf.ones_like(actuals)</span><br><span class="line">zeros_like_actuals = tf.zeros_like(actuals)</span><br><span class="line">ones_like_predictions = tf.ones_like(predictions)</span><br><span class="line">zeros_like_predictions = tf.zeros_like(predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照前面的计算公式编写如下计算代码</span></span><br><span class="line"></span><br><span class="line">tp_op = tf.reduce_sum(tf.cast(tf.logical_and(</span><br><span class="line">            tf.equal(actuals, ones_like_actuals),</span><br><span class="line">            tf.equal(predictions, ones_like_predictions)),<span class="string">"float"</span>))</span><br><span class="line"> </span><br><span class="line">tn_op = tf.reduce_sum(tf.cast(tf.logical_and(</span><br><span class="line">            tf.equal(actuals, zeros_like_actuals),</span><br><span class="line">            tf.equal(predictions, zeros_like_predictions)),<span class="string">"float"</span>))</span><br><span class="line"> </span><br><span class="line">fp_op = tf.reduce_sum(tf.cast(tf.logical_and(</span><br><span class="line">            tf.equal(actuals, zeros_like_actuals),</span><br><span class="line">            tf.equal(predictions, ones_like_predictions)),<span class="string">"float"</span>))</span><br><span class="line"> </span><br><span class="line">fn_op = tf.reduce_sum(tf.cast(tf.logical_and(</span><br><span class="line">            tf.equal(actuals, ones_like_actuals),</span><br><span class="line">            tf.equal(predictions, zeros_like_predictions)),<span class="string">"float"</span>))</span><br><span class="line">            </span><br><span class="line">tp, tn, fp, fn = session.run([tp_op, tn_op, fp_op, fn_op], feed_dict)</span><br><span class="line">tpr = float(tp)/(float(tp) + float(fn))</span><br><span class="line">fpr = float(fp)/(float(fp) + float(tn))</span><br><span class="line">fnr = float(fn)/(float(tp) + float(fn))</span><br><span class="line">accuracy = (float(tp) + float(tn))/(float(tp) + float(fp) + float(fn) + float(tn))</span><br><span class="line">recall = tpr</span><br><span class="line">precision = float(tp)/(float(tp) + float(fp))</span><br><span class="line">f1_score = (<span class="number">2</span> * (precision * recall)) / (precision + recall)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;基本内容&quot;&gt;&lt;a href=&quot;#基本内容&quot; class=&quot;headerlink&quot; title=&quot;基本内容&quot;&gt;&lt;/a&gt;基本内容&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;True真&amp;emsp; False假&amp;emsp;Positive正&amp;emsp;Negative负&lt;/stro
      
    
    </summary>
    
    
    
      <category term="机器学习" scheme="http://pl741.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
